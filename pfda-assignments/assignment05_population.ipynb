{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10738045",
   "metadata": {},
   "source": [
    "#### Author: FaolÃ¡n Hamilton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7e610",
   "metadata": {},
   "source": [
    "## Part 1 70%\n",
    "Write a jupyter notebook that analyses the differences between the sexes by age in Ireland.\n",
    "\n",
    "- Weighted mean age (by sex)\n",
    "- The difference between the sexes by age\n",
    "This part does not need to look at the regions.\n",
    "\n",
    "i.e. You can take the notebook I used in the lectures and substitute the sexes for the regions.\n",
    "\n",
    "## Part 2 20%\n",
    "- In the same notebook, make a variable that stores an age (say 35).\n",
    "\n",
    "- Write that code that would group the people within 5 years of that age together, into one age group \n",
    "\n",
    "- Calculate the population difference between the sexes in that age group.\n",
    "\n",
    "## Part 3 10%\n",
    "In the same notebook.\n",
    "\n",
    "- Write the code that would work out which region in Ireland has the biggest population difference between the sexes in that age group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d84557",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a67f8",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "- This notebook is for assignment 5 of the Programming for Data Analytics module. This structure has been edited from the 'weighted stats' notebook created by Andrew Beatty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is bringing in modules used in this notebook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the dataset with the ages broken down by sex in Ireland\n",
    "url = \"C:\\Users\\ClaireReilly\\Downloads\"\n",
    "#Read in the url as a csv\n",
    "df = pd.read_csv(url)\n",
    "#Show the last three rows of data\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f0d26",
   "metadata": {},
   "source": [
    "The data currently list out all Local Authorities in the output. For the first section, I want to create a subset of this dataset using only Ireland level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56590813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only need data for Ireland, so the other rows can be removed for now\n",
    "df = df[df[\"Administrative Counties\"] == \"Ireland\"]\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2ecc6",
   "metadata": {},
   "source": [
    "There are a lot of columns in the dataset, but we only need 'Sex', Single Year of Age' and 'VALUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the columns in the dataset to identify which to remove\n",
    "headers = df.columns.tolist()\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the headers that are not relevant\n",
    "drop_col_list = ['STATISTIC', 'Statistic Label','TLIST(A1)','CensusYear','C02199V02655','C02076V03371','C03789V04537','UNIT']\n",
    "df.drop(columns=drop_col_list, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cabc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improve the naming convention of the 'Single Year of Age'\n",
    "df = df[df[\"Single Year of Age\"] != \"All ages\"]\n",
    "#Change 'Under 1 year' to '0'\n",
    "df['Single Year of Age'] = df['Single Year of Age'].str.replace('Under 1 year', '0')\n",
    "df['Single Year of Age'] = df['Single Year of Age'].str.replace('\\\\D', '', regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe27435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure 'Single Year of Age' and 'VALUE' are integers\n",
    "df['Single Year of Age']=df['Single Year of Age'].astype('int64')\n",
    "df['VALUE']=df['VALUE'].astype('int64')\n",
    "#print (df.head(3))\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12868c0a",
   "metadata": {},
   "source": [
    "I wanted to ensure the csv output values were rounded to whole values and found this Stackoverflow (https://stackoverflow.com/questions/76584654/python-pandas-to-csv-is-rounding-any-way-for-it-to-not-round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeddb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.pivot_table(df,'VALUE',\"Single Year of Age\", 'Sex')\n",
    "# write out the entire file to local machine\n",
    "df_analysis.to_csv(f\"assignment05_population_for_analysis.csv\", float_format='%.0f')\n",
    "print (df_analysis.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c9a06",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2024b25",
   "metadata": {},
   "source": [
    "## Now we can do weighted descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = list(df_analysis.columns)\n",
    "district = headers[0]\n",
    "district"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99d790",
   "metadata": {},
   "source": [
    "Weighted mean is sum(age*population at age) / sum (populations at age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_people = df_analysis[district].sum()\n",
    "number_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a493756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumages = df_analysis[district].mul(df_analysis.index, axis=0).sum()\n",
    "cumages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e08823",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean = cumages/number_people\n",
    "weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5004e",
   "metadata": {},
   "source": [
    "#### Or you can use numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff30280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w_mean = np.average(df_analysis.index, weights=df_analysis[district])\n",
    "w_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e2ba6",
   "metadata": {},
   "source": [
    "### weighted median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313d52f",
   "metadata": {},
   "source": [
    "    create a series of the cumlative sums and find the index of the middle value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = df_analysis[district].cumsum()\n",
    "cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all the number of people\n",
    "cutoff = df_analysis[district].sum()/2\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis[district][cumsum>=cutoff].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcefd19",
   "metadata": {},
   "source": [
    "## Weighted standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319639a0",
   "metadata": {},
   "source": [
    "The is the same formula as the normal standard deviation, just with weights applied to the differenced to the weight mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ee7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect way\n",
    "df_analysis[district].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c634b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect\n",
    "df_analysis[district].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91390c4c",
   "metadata": {},
   "source": [
    "We need the weighted std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "w_mean = np.average(df_analysis.index, weights=df_analysis[district])\n",
    "w_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_variance = np.average((df_analysis.index - w_mean)**2, weights= df_analysis[district])\n",
    "w_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_std = np.sqrt(w_variance)\n",
    "w_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
